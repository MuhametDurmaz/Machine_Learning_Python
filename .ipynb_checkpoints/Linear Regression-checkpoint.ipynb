{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import copy\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement\n",
    "Suppose you are the CEO of a restaurant franchise and are considering different cities for opening a new outlet.\n",
    "\n",
    "You would like to expand your business to cities that may give your restaurant higher profits.\n",
    "The chain already has restaurants in various cities and you have data for profits and populations from the cities.\n",
    "You also have data on cities that are candidates for a new restaurant.\n",
    "For these cities, you have the city population.\n",
    "Can you use the data to help you identify which cities may potentially give your business higher profits?\n",
    "\n",
    "Dataset\n",
    "You will start by loading the dataset for this task.\n",
    "\n",
    "The load_data() function shown below loads the data into variables x_train and y_train\n",
    "x_train is the population of a city\n",
    "y_train is the profit of a restaurant in that city. A negative value for profit indicates a loss.\n",
    "Both X_train and y_train are numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "x_train, y_train = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the compute_cost below to:\n",
    "\n",
    "Iterate over the training examples, and for each example, compute:\n",
    "\n",
    "The prediction of the model for that example\n",
    "𝑓𝑤𝑏(𝑥(𝑖))=𝑤𝑥(𝑖)+𝑏\n",
    " \n",
    "The cost for that example\n",
    "𝑐𝑜𝑠𝑡(𝑖)=(𝑓𝑤𝑏−𝑦(𝑖))2\n",
    " \n",
    "Return the total cost over all examples\n",
    "𝐽(𝐰,𝑏)=12𝑚∑𝑖=0𝑚−1𝑐𝑜𝑠𝑡(𝑖)\n",
    " \n",
    "Here,  𝑚  is the number of training examples and  ∑  is the summation operator\n",
    "If you get stuck, you can check out the hints presented after the cell below to help you with the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for computing the cost\n",
    "def compute_cost(x, y, w, b): \n",
    "\n",
    "    m = x.shape[0] \n",
    "    \n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        cost = (w*x[i]+b-y[i])**2\n",
    "        total_cost+=cost/(2*m)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete the compute_gradient function to:\n",
    "\n",
    "Iterate over the training examples, and for each example, compute:\n",
    "\n",
    "The prediction of the model for that example\n",
    "𝑓𝑤𝑏(𝑥(𝑖))=𝑤𝑥(𝑖)+𝑏\n",
    " \n",
    "The gradient for the parameters  𝑤,𝑏  from that example\n",
    "∂𝐽(𝑤,𝑏)∂𝑏(𝑖)=(𝑓𝑤,𝑏(𝑥(𝑖))−𝑦(𝑖))\n",
    " \n",
    "∂𝐽(𝑤,𝑏)∂𝑤(𝑖)=(𝑓𝑤,𝑏(𝑥(𝑖))−𝑦(𝑖))𝑥(𝑖)\n",
    " \n",
    "Return the total gradient update from all the examples\n",
    "∂𝐽(𝑤,𝑏)∂𝑏=1𝑚∑𝑖=0𝑚−1∂𝐽(𝑤,𝑏)∂𝑏(𝑖)\n",
    " \n",
    "∂𝐽(𝑤,𝑏)∂𝑤=1𝑚∑𝑖=0𝑚−1∂𝐽(𝑤,𝑏)∂𝑤(𝑖)\n",
    " \n",
    "Here,  𝑚  is the number of training examples and  ∑  is the summation operator\n",
    "If you get stuck, you can check out the hints presented after the cell below to help you with the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for calculating the gradients\n",
    "def compute_gradient(x, y, w, b): \n",
    "\n",
    "    m = x.shape[0]\n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "\n",
    "    for i in range(m):\n",
    "        dj_dw += (w*x[i]+b-y[i])*x[i]/m\n",
    "        dj_db += (w*x[i]+b-y[i])/m\n",
    "\n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for optimizing the regression coefficient w,b\n",
    "def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \n",
    "    m = len(x)\n",
    "\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    w = copy.deepcopy(w_in) \n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        dj_dw, dj_db = gradient_function(x, y, w, b )  \n",
    "\n",
    "        w = w - alpha * dj_dw               \n",
    "        b = b - alpha * dj_db               \n",
    "\n",
    "        if i<100000:   \n",
    "            cost =  cost_function(x, y, w, b)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        if i% math.ceil(num_iters/10) == 0:\n",
    "            w_history.append(w)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
    "        \n",
    "    return w, b, J_history, w_history "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
